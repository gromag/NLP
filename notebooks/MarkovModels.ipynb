{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Sequence tagging using Markov Models and Baum-Welch probability\n",
    "\n"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "source": [
    "def transition_prob(a, b):\n",
    "    \"\"\"Equiprobable between all tokens, S is special case there is no transition to S\"\"\"\n",
    "    return 1/3\n",
    "\n",
    "def calculate_tag_sequences(phrase, Vocab):\n",
    "    \"\"\"\n",
    "    Get's a phrase and a vocabulary and calculates all possible hidden states\n",
    "    and their probabilities\n",
    "    Example output:\n",
    "    [[('S', 1.0), ('O', 0.33), ('N', 0.5), ('V', 0.5), ('O', 0.33), ('N', 0.5)], \n",
    "    [('S', 1.0), ('O', 0.33), ('N', 0.5), ('V', 0.5), ('O', 0.33), ('V', 0.5)], \n",
    "    [('S', 1.0), ('O', 0.33), ('O', 0.33), ('V', 0.5), ('O', 0.33), ('N', 0.5)], \n",
    "    [('S', 1.0), ('O', 0.33), ('O', 0.33), ('V', 0.5), ('O', 0.33), ('V', 0.5)]]\n",
    "    \n",
    "    \"\"\"\n",
    "    output = [[]]\n",
    "    tokens = phrase.split()\n",
    "    for t in tokens:\n",
    "        token_tags = []\n",
    "        for v in Vocab:\n",
    "            if t in Vocab[v]:\n",
    "                p_w_given_t = 1/len(Vocab[v])\n",
    "                token_tags.append((v, p_w_given_t))\n",
    "        \n",
    "\n",
    "        tmp_output = []\n",
    "        for i in range(len(output)):\n",
    "            for tt in range(len(token_tags)):\n",
    "                tmp_output.append( output[i]+ [token_tags[tt]])\n",
    "        \n",
    "        output = tmp_output\n",
    "    \n",
    "    return output\n",
    "\n",
    "def calculate_tag_sequence_prob(sequence):\n",
    "    prob = 1.0\n",
    "    prev_step = \"\"\n",
    "    for step in range(1, len(sequence)):\n",
    "        prob *= transition_prob(sequence[step-1][0], sequence[step][0]) * sequence[step][1]\n",
    "\n",
    "    return prob\n",
    "\n",
    "def calculate_sequence_name(s):\n",
    "    \"\"\"\n",
    "        Takes as input a list like:\n",
    "        [(\"A\", 0.3),(\"B\", 0.2),(\"C\", 0.5)]\n",
    "        returns\n",
    "        \"ABC\"\n",
    "    \"\"\"\n",
    "    letters = map((lambda x: x[0]), s)\n",
    "    combined = reduce((lambda x, y: x + y), letters )\n",
    "    return combined\n",
    "\n",
    "def calculate_baum_welch_prob(prob_dict, ab):\n",
    "    \"\"\"\n",
    "    Calculate the Baum-Welch probability of a state given its previous state.\n",
    "    Passed in are the calculated markov model probabilities\n",
    "    e.g. P(V|O) is expressed as \"OV\"\n",
    "\n",
    "    Input:\n",
    "    prob_dict e.g. {'SONVON': 0.3, 'SONVOV': 0.3, 'SOOVON': 0.2, 'SOOVOV': 0.2}\n",
    "    ab e.g. \"OV\"\n",
    "\n",
    "    See https://www.coursera.org/learn/language-processing/supplement/CROHj/probabilities-of-tag-sequences-in-hmms\n",
    "    \"\"\"\n",
    "    prob_numerator = 0\n",
    "    prob_denominator = 0\n",
    "\n",
    "    for name in prob_dict:\n",
    "        count1 = 0\n",
    "        count2 = 0\n",
    "        for i in range(len(name)-1):\n",
    "            token = name[i:i+2]\n",
    "            # print(token)\n",
    "            if ab == token:\n",
    "                count1 += 1\n",
    "            if token.startswith(ab[0:1]):\n",
    "                count2 += 1\n",
    "\n",
    "        prob_numerator += count1 * prob_dict[name]\n",
    "        prob_denominator += count2 * prob_dict[name]\n",
    "        assert(prob_denominator > 0)\n",
    "    return prob_numerator/prob_denominator"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "source": [
    "from functools import reduce\n",
    "\n",
    "Vocab = {\n",
    "    \"N\": [\"mimsy\", \"borogoves\"],\n",
    "    \"V\": [\"were\", \"borogoves\"],\n",
    "    \"O\": [\"all\", \"mimsy\", \"the\"],\n",
    "    \"S\": [\"<s>\"]\n",
    "}\n",
    "\n",
    "Phrase = \"<s> all mimsy were the borogoves\""
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "source": [
    "sequences = calculate_tag_sequences(Phrase, Vocab)\n",
    "print(sequences)\n"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[[('S', 1.0), ('O', 0.3333333333333333), ('N', 0.5), ('V', 0.5), ('O', 0.3333333333333333), ('N', 0.5)], [('S', 1.0), ('O', 0.3333333333333333), ('N', 0.5), ('V', 0.5), ('O', 0.3333333333333333), ('V', 0.5)], [('S', 1.0), ('O', 0.3333333333333333), ('O', 0.3333333333333333), ('V', 0.5), ('O', 0.3333333333333333), ('N', 0.5)], [('S', 1.0), ('O', 0.3333333333333333), ('O', 0.3333333333333333), ('V', 0.5), ('O', 0.3333333333333333), ('V', 0.5)]]\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "source": [
    "sequences_prob = [ calculate_tag_sequence_prob(seq)  for seq in sequences]\n",
    "print(sequences_prob)\n"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[5.715592135345221e-05, 5.715592135345221e-05, 3.810394756896814e-05, 3.810394756896814e-05]\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "source": [
    "norm_sequences_prob = { calculate_sequence_name(seq[0]) : seq[1] / sum(sequences_prob) for seq in zip(sequences, sequences_prob)}\n",
    "print(norm_sequences_prob)\n"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "{'SONVON': 0.3, 'SONVOV': 0.3, 'SOOVON': 0.2, 'SOOVOV': 0.2}\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Baum Welch probability"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "source": [
    "\n",
    "calculate_baum_welch_prob(norm_sequences_prob, \"OV\")"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "0.37499999999999994"
      ]
     },
     "metadata": {},
     "execution_count": 6
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {}
  }
 ],
 "metadata": {
  "orig_nbformat": 4,
  "language_info": {
   "name": "python",
   "version": "3.9.7",
   "mimetype": "text/x-python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "pygments_lexer": "ipython3",
   "nbconvert_exporter": "python",
   "file_extension": ".py"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.9.2 64-bit"
  },
  "interpreter": {
   "hash": "aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}